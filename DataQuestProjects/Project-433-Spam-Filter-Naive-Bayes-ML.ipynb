{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SMS Spam Filter\n",
    "\n",
    "The goal of this project is to **build a spam filter for SMS messages.**\n",
    "\n",
    "To be able to do it we need to achive the following four steps. We need to make sure that the computer:\n",
    "1. Learns how humans classify messages.\n",
    "2. Uses that human knowledge to estimate probabilities for new messages — probabilities for spam and non-spam.\n",
    "3. Classifies a new message based on these probability values. If the probability for spam is greater, then it classifies the message as spam. Otherwise, it classifies it as non-spam (if the two probability values are equal, then we may need a human to classify the message).\n",
    "\n",
    "Our first task is to **\"teach\" the computer how to classify messages**. To do that, we'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans.\n",
    "\n",
    "**DATASET**\n",
    "The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) or directy from [this link](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection). The data collection process is described in more details on [this page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where find some of the authors' papers can be found.\n",
    "\n",
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_spam = pd.read_csv('SMSSpamCollection', \n",
    "                      sep='\\t', \n",
    "                      header=None,\n",
    "                      names = ['Label','SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore how many of each there are\n",
    "sms_spam['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13.4% spam and 86.6% non-spam ('ham') messages in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Test definition\n",
    "Once our spam filter is done, we'll **need to test how good it is** with classifying new messages. To test the spam filter, we're first going to split our dataset into two categories:\n",
    "\n",
    "- **A training set**, which we'll use to \"train\" the computer how to classify messages.\n",
    "- **A test set**, which we'll use to test how good the spam filter is with classifying new messages.\n",
    "\n",
    "We're going to keep **80% of our dataset for training**, and **20% for testing** (we want to train the algorithm on as much data as possible, but we also want to have enough test data). The dataset has 5,572 messages, which means that:\n",
    "\n",
    "- The training set will have 4,458 messages (about 80% of the dataset).\n",
    "- The test set will have 1,114 messages (about 20% of the dataset).\n",
    "\n",
    "We're going to start by randomizing the entire dataset to ensure that spam and ham messages are spread properly throughout the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomisethe whole set\n",
    "randomised = sms_spam.sample(frac=1, random_state=1)\n",
    "\n",
    "#select 80% for training\n",
    "training = randomised.sample(frac=0.8)\n",
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(970, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract training fromthe full df to create a test set\n",
    "#using concat\n",
    "test = pd.concat([randomised,training]).drop_duplicates(keep=False)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected result was 1114, unsure why there were more duplicates here that got dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if the regular samplin returns correct result\n",
    "test_2 = randomised.sample(frac=0.2)\n",
    "test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating test set using difference\n",
    "test_3 = randomised.loc[randomised.index.difference(training.index)]\n",
    "test_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating test set using disjunctive union\n",
    "test_4 = randomised.loc[randomised.index ^  training.index]\n",
    "test_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both return the correct number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_4\n",
    "\n",
    "#check % of spam/ham in both sets\n",
    "test_percent = test_set['Label'].value_counts(normalize=True)\n",
    "training_percent = training['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn into dfs to compare \n",
    "df1 = test_percent.rename_axis('label').reset_index(name='percent_test')\n",
    "df2 = training_percent.rename_axis('label').reset_index(name='Percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>percent_test</th>\n",
       "      <th>percent_training</th>\n",
       "      <th>percent_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>0.868941</td>\n",
       "      <td>0.865186</td>\n",
       "      <td>0.865937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>0.131059</td>\n",
       "      <td>0.134814</td>\n",
       "      <td>0.134063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  percent_test  percent_training  percent_original\n",
       "0   ham      0.868941          0.865186          0.865937\n",
       "1  spam      0.131059          0.134814          0.134063"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['percent_training'] = df2['Percent']\n",
    "\n",
    "#add original percentages to compare with tes & training\n",
    "original_percent = sms_spam['Label'].value_counts(normalize=True).rename_axis('label').reset_index(name='percent_original')\n",
    "df1['percent_original'] = original_percent['percent_original']\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13.4% spam and 86.6% non-spam ('ham') messages in the original dataset. The values in the test and training datasets are similar: spam 12% and 13.3%, non spam 88% and 86.7% respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "To bring the data in a format that will allow us to extract easily all the information we need, we'll need to perform data cleaning.\n",
    "\n",
    "We'll standardise the messages in the SMS column and then transform it so that each word becomes its own column. The index will then indicate hw many times a given word occurs in each spam/ham message.\n",
    "\n",
    "First we remove the punctuation and bring all the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4102    gsoh  good with spam the ladies u could b a ma...\n",
       "2857    japanese proverb  if one can do it  u too can ...\n",
       "3238    ron say fri leh  n he said ding tai feng cant ...\n",
       "5239          jay wants to work out first  how s 4 sound \n",
       "5506    god s love has no limit  god s grace has no me...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert into string\n",
    "#standardise case\n",
    "training['SMS'] = training['SMS'].astype(str).str.lower()\n",
    "\n",
    "#remove all unwanted characters\n",
    "import re\n",
    "training['SMS'].replace('\\W',' ',regex=True, inplace = True)\n",
    "\n",
    "#check if worked\n",
    "training['SMS'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of unique words is a vocabulary\n",
    "#create a vocab from all words in the SMS col\n",
    "\n",
    "#split sms into lists\n",
    "training['SMS'] = training['SMS'].astype(str).str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72429"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for row in training['SMS']:\n",
    "    for word in row:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform into a set to remove duplicates\n",
    "vocabulary = set(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7757"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform back into list\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictonary with occurence of each word per row\n",
    "\n",
    "#create a dictionary with all words, where:\n",
    "    #each key is a unique word (a string) from the vocabulary, and \n",
    "    #each value is a list of the length of training set, \n",
    "    #each element in the list is a 0\n",
    "\n",
    "word_count_per_sms = {unique_word: [0] * len(training['SMS']) for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sms in enumerate(training['SMS']):\n",
    "    for word in sms:\n",
    "        word_count_per_sms[word][index] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nearly</th>\n",
       "      <th>yuo</th>\n",
       "      <th>ve</th>\n",
       "      <th>w1jhl</th>\n",
       "      <th>50p</th>\n",
       "      <th>wine</th>\n",
       "      <th>punishment</th>\n",
       "      <th>missed</th>\n",
       "      <th>difference</th>\n",
       "      <th>using</th>\n",
       "      <th>...</th>\n",
       "      <th>80122300p</th>\n",
       "      <th>strips</th>\n",
       "      <th>chloe</th>\n",
       "      <th>mike</th>\n",
       "      <th>sweatter</th>\n",
       "      <th>cheetos</th>\n",
       "      <th>others</th>\n",
       "      <th>dey</th>\n",
       "      <th>yan</th>\n",
       "      <th>stopbcm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7757 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nearly  yuo  ve  w1jhl  50p  wine  punishment  missed  difference  using  \\\n",
       "0       0    0   0      0    0     0           0       0           0      0   \n",
       "1       0    0   0      0    0     0           0       0           0      0   \n",
       "2       0    0   0      0    0     0           0       0           0      0   \n",
       "3       0    0   0      0    0     0           0       0           0      0   \n",
       "4       0    0   0      0    0     0           0       0           0      0   \n",
       "\n",
       "   ...  80122300p  strips  chloe  mike  sweatter  cheetos  others  dey  yan  \\\n",
       "0  ...          0       0      0     0         0        0       0    0    0   \n",
       "1  ...          0       0      0     0         0        0       0    0    0   \n",
       "2  ...          0       0      0     0         0        0       0    0    0   \n",
       "3  ...          0       0      0     0         0        0       0    0    0   \n",
       "4  ...          0       0      0     0         0        0       0    0    0   \n",
       "\n",
       "   stopbcm  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 7757 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_sms = pd.DataFrame(word_count_per_sms)\n",
    "\n",
    "wc_sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4458 entries, 0 to 4457\n",
      "Columns: 7757 entries, nearly to stopbcm\n",
      "dtypes: int64(7757)\n",
      "memory usage: 263.8 MB\n"
     ]
    }
   ],
   "source": [
    "wc_sms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for nans\n",
    "wc_sms.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No NaNs in the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4102</td>\n",
       "      <td>spam</td>\n",
       "      <td>[gsoh, good, with, spam, the, ladies, u, could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2857</td>\n",
       "      <td>ham</td>\n",
       "      <td>[japanese, proverb, if, one, can, do, it, u, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3238</td>\n",
       "      <td>ham</td>\n",
       "      <td>[ron, say, fri, leh, n, he, said, ding, tai, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5239</td>\n",
       "      <td>ham</td>\n",
       "      <td>[jay, wants, to, work, out, first, how, s, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5506</td>\n",
       "      <td>ham</td>\n",
       "      <td>[god, s, love, has, no, limit, god, s, grace, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "4102  spam  [gsoh, good, with, spam, the, ladies, u, could...\n",
       "2857   ham  [japanese, proverb, if, one, can, do, it, u, t...\n",
       "3238   ham  [ron, say, fri, leh, n, he, said, ding, tai, f...\n",
       "5239   ham  [jay, wants, to, work, out, first, how, s, 4, ...\n",
       "5506   ham  [god, s, love, has, no, limit, god, s, grace, ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>nearly</th>\n",
       "      <th>yuo</th>\n",
       "      <th>ve</th>\n",
       "      <th>w1jhl</th>\n",
       "      <th>50p</th>\n",
       "      <th>wine</th>\n",
       "      <th>punishment</th>\n",
       "      <th>missed</th>\n",
       "      <th>...</th>\n",
       "      <th>80122300p</th>\n",
       "      <th>strips</th>\n",
       "      <th>chloe</th>\n",
       "      <th>mike</th>\n",
       "      <th>sweatter</th>\n",
       "      <th>cheetos</th>\n",
       "      <th>others</th>\n",
       "      <th>dey</th>\n",
       "      <th>yan</th>\n",
       "      <th>stopbcm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4102</td>\n",
       "      <td>spam</td>\n",
       "      <td>[gsoh, good, with, spam, the, ladies, u, could...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2857</td>\n",
       "      <td>ham</td>\n",
       "      <td>[japanese, proverb, if, one, can, do, it, u, t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3238</td>\n",
       "      <td>ham</td>\n",
       "      <td>[ron, say, fri, leh, n, he, said, ding, tai, f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5239</td>\n",
       "      <td>ham</td>\n",
       "      <td>[jay, wants, to, work, out, first, how, s, 4, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5506</td>\n",
       "      <td>ham</td>\n",
       "      <td>[god, s, love, has, no, limit, god, s, grace, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7759 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS  nearly  yuo  \\\n",
       "4102  spam  [gsoh, good, with, spam, the, ladies, u, could...     0.0  0.0   \n",
       "2857   ham  [japanese, proverb, if, one, can, do, it, u, t...     0.0  0.0   \n",
       "3238   ham  [ron, say, fri, leh, n, he, said, ding, tai, f...     0.0  0.0   \n",
       "5239   ham  [jay, wants, to, work, out, first, how, s, 4, ...     NaN  NaN   \n",
       "5506   ham  [god, s, love, has, no, limit, god, s, grace, ...     NaN  NaN   \n",
       "\n",
       "       ve  w1jhl  50p  wine  punishment  missed  ...  80122300p  strips  \\\n",
       "4102  0.0    0.0  0.0   0.0         0.0     0.0  ...        0.0     0.0   \n",
       "2857  0.0    0.0  0.0   0.0         0.0     0.0  ...        0.0     0.0   \n",
       "3238  0.0    0.0  0.0   0.0         0.0     0.0  ...        0.0     0.0   \n",
       "5239  NaN    NaN  NaN   NaN         NaN     NaN  ...        NaN     NaN   \n",
       "5506  NaN    NaN  NaN   NaN         NaN     NaN  ...        NaN     NaN   \n",
       "\n",
       "      chloe  mike  sweatter  cheetos  others  dey  yan  stopbcm  \n",
       "4102    0.0   0.0       0.0      0.0     0.0  0.0  0.0      0.0  \n",
       "2857    0.0   0.0       0.0      0.0     0.0  0.0  0.0      0.0  \n",
       "3238    0.0   0.0       0.0      0.0     0.0  0.0  0.0      0.0  \n",
       "5239    NaN   NaN       NaN      NaN     NaN  NaN  NaN      NaN  \n",
       "5506    NaN   NaN       NaN      NaN     NaN  NaN  NaN      NaN  \n",
       "\n",
       "[5 rows x 7759 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note: attempting to use concat function caused the kernel to die (multiple tries)\n",
    "#using join instead\n",
    "joined = training.join(wc_sms, how='left')\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suddenly there are NaNs and integers have been turned into floats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label        0\n",
       "SMS          0\n",
       "nearly     897\n",
       "yuo        897\n",
       "ve         897\n",
       "          ... \n",
       "cheetos    897\n",
       "others     897\n",
       "dey        897\n",
       "yan        897\n",
       "stopbcm    897\n",
       "Length: 7759, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>nearly</th>\n",
       "      <th>yuo</th>\n",
       "      <th>ve</th>\n",
       "      <th>w1jhl</th>\n",
       "      <th>50p</th>\n",
       "      <th>wine</th>\n",
       "      <th>punishment</th>\n",
       "      <th>missed</th>\n",
       "      <th>...</th>\n",
       "      <th>80122300p</th>\n",
       "      <th>strips</th>\n",
       "      <th>chloe</th>\n",
       "      <th>mike</th>\n",
       "      <th>sweatter</th>\n",
       "      <th>cheetos</th>\n",
       "      <th>others</th>\n",
       "      <th>dey</th>\n",
       "      <th>yan</th>\n",
       "      <th>stopbcm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7759 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  nearly  yuo   ve  \\\n",
       "0   ham  [go, until, jurong, point, crazy, available, o...     0.0  0.0  0.0   \n",
       "1   ham                     [ok, lar, joking, wif, u, oni]     0.0  0.0  0.0   \n",
       "2   NaN                                                NaN     0.0  0.0  0.0   \n",
       "3   ham  [u, dun, say, so, early, hor, u, c, already, t...     0.0  0.0  0.0   \n",
       "4   ham  [nah, i, don, t, think, he, goes, to, usf, he,...     0.0  0.0  0.0   \n",
       "\n",
       "   w1jhl  50p  wine  punishment  missed  ...  80122300p  strips  chloe  mike  \\\n",
       "0    0.0  0.0   0.0         0.0     0.0  ...        0.0     0.0    0.0   0.0   \n",
       "1    0.0  0.0   0.0         0.0     0.0  ...        0.0     0.0    0.0   0.0   \n",
       "2    0.0  0.0   0.0         0.0     0.0  ...        0.0     0.0    0.0   0.0   \n",
       "3    0.0  0.0   0.0         0.0     0.0  ...        0.0     0.0    0.0   0.0   \n",
       "4    0.0  0.0   0.0         0.0     0.0  ...        0.0     0.0    0.0   0.0   \n",
       "\n",
       "   sweatter  cheetos  others  dey  yan  stopbcm  \n",
       "0       0.0      0.0     0.0  0.0  0.0      0.0  \n",
       "1       0.0      0.0     0.0  0.0  0.0      0.0  \n",
       "2       0.0      0.0     0.0  0.0  0.0      0.0  \n",
       "3       0.0      0.0     0.0  0.0  0.0      0.0  \n",
       "4       0.0      0.0     0.0  0.0  0.0      0.0  \n",
       "\n",
       "[5 rows x 7759 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_training = pd.concat([training,wc_sms], axis=1)\n",
    "wc_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for nans\n",
    "wc_training.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3857\n",
       "NaN      897\n",
       "spam     601\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_training['Label'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the NaNs seem to be in the label & sms fields, we can just drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_training = wc_training.dropna(subset=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_training.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    4458\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_training['Label'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3561\n",
       "True      897\n",
       "Name: tea, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_training['tea'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**this section not useful in the end, but kept for reference**\n",
    "\n",
    "Will try to do the same but reset index first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_no_index = training.reset_index(drop=True)\n",
    "wc_no_index = wc_training.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_concat = pd.concat([t_no_index, wc_no_index], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>nearly</th>\n",
       "      <th>yuo</th>\n",
       "      <th>ve</th>\n",
       "      <th>w1jhl</th>\n",
       "      <th>50p</th>\n",
       "      <th>wine</th>\n",
       "      <th>...</th>\n",
       "      <th>80122300p</th>\n",
       "      <th>strips</th>\n",
       "      <th>chloe</th>\n",
       "      <th>mike</th>\n",
       "      <th>sweatter</th>\n",
       "      <th>cheetos</th>\n",
       "      <th>others</th>\n",
       "      <th>dey</th>\n",
       "      <th>yan</th>\n",
       "      <th>stopbcm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "      <td>[gsoh, good, with, spam, the, ladies, u, could...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[japanese, proverb, if, one, can, do, it, u, t...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ham</td>\n",
       "      <td>[ron, say, fri, leh, n, he, said, ding, tai, f...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS Label  \\\n",
       "0  spam  [gsoh, good, with, spam, the, ladies, u, could...   ham   \n",
       "1   ham  [japanese, proverb, if, one, can, do, it, u, t...   ham   \n",
       "2   ham  [ron, say, fri, leh, n, he, said, ding, tai, f...   ham   \n",
       "\n",
       "                                                 SMS  nearly  yuo   ve  w1jhl  \\\n",
       "0  [go, until, jurong, point, crazy, available, o...     0.0  0.0  0.0    0.0   \n",
       "1                     [ok, lar, joking, wif, u, oni]     0.0  0.0  0.0    0.0   \n",
       "2  [u, dun, say, so, early, hor, u, c, already, t...     0.0  0.0  0.0    0.0   \n",
       "\n",
       "   50p  wine  ...  80122300p  strips  chloe  mike  sweatter  cheetos  others  \\\n",
       "0  0.0   0.0  ...        0.0     0.0    0.0   0.0       0.0      0.0     0.0   \n",
       "1  0.0   0.0  ...        0.0     0.0    0.0   0.0       0.0      0.0     0.0   \n",
       "2  0.0   0.0  ...        0.0     0.0    0.0   0.0       0.0      0.0     0.0   \n",
       "\n",
       "   dey  yan  stopbcm  \n",
       "0  0.0  0.0      0.0  \n",
       "1  0.0  0.0      0.0  \n",
       "2  0.0  0.0      0.0  \n",
       "\n",
       "[3 rows x 7761 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_concat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_concat.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2542\n",
       "NaN     897\n",
       "1.0     739\n",
       "2.0     177\n",
       "3.0      66\n",
       "4.0      16\n",
       "5.0      15\n",
       "6.0       3\n",
       "7.0       2\n",
       "8.0       1\n",
       "Name: you, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined['you'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However we join the databases there are stll 906 NaNs. We will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_training.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_training.isna().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate probabilities\n",
    "\n",
    "We'll calculate all the parameters using the equations below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\[P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\\\\]\n",
    "\n",
    "\\\\[P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate P(wi|Spam) and P(wi|Ham) we need to classify the new messages using these formulas:\n",
    "\n",
    "\\\\[P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam) \\\\]\n",
    "\\\\[P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first calculate:\n",
    "\n",
    "* P(Spam), P(Ham)\n",
    "* n_spam, n_ham, n_vocabulary\n",
    "\n",
    "Notes:\n",
    "- *n_spam* is equal to the number of words in all the spam messages — it's not equal to the number of spam messages, and it's not equal to the total number of unique words in spam messages.\n",
    "\n",
    "- *n_ham* is equal to the number of words in all the non-spam messages — it's not equal to the number of non-spam messages, and it's not equal to the total number of unique words in non-spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that a message is a spam one is around 13.42 %, and the probability that it's ham is around 86.58 %.\n"
     ]
    }
   ],
   "source": [
    "#P(Spam)\n",
    "p_spam = (len(wc_training[wc_training['Label']=='spam']) / len(wc_training)) \n",
    "p_spam_100 = (len(wc_training[wc_training['Label']=='spam']) / len(wc_training))*100\n",
    "\n",
    "#P(Ham)\n",
    "p_ham = 1 - p_spam\n",
    "p_ham_100 = 100 - p_spam_100\n",
    "\n",
    "print(\"The probability that a message is a spam one is around\", round(p_spam_100,2), \n",
    "      \"%, and the probability that it's ham is around\", round(p_ham_100,2), \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13423195731536086 0.8657680426846391\n"
     ]
    }
   ],
   "source": [
    "print(p_spam, p_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>nearly</th>\n",
       "      <th>yuo</th>\n",
       "      <th>ve</th>\n",
       "      <th>w1jhl</th>\n",
       "      <th>50p</th>\n",
       "      <th>wine</th>\n",
       "      <th>punishment</th>\n",
       "      <th>missed</th>\n",
       "      <th>...</th>\n",
       "      <th>strips</th>\n",
       "      <th>chloe</th>\n",
       "      <th>mike</th>\n",
       "      <th>sweatter</th>\n",
       "      <th>cheetos</th>\n",
       "      <th>others</th>\n",
       "      <th>dey</th>\n",
       "      <th>yan</th>\n",
       "      <th>stopbcm</th>\n",
       "      <th>words_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>spam</td>\n",
       "      <td>[freemsg, hey, there, darling, it, s, been, 3,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7760 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  nearly  yuo   ve  \\\n",
       "0   ham  [go, until, jurong, point, crazy, available, o...     0.0  0.0  0.0   \n",
       "1   ham                     [ok, lar, joking, wif, u, oni]     0.0  0.0  0.0   \n",
       "3   ham  [u, dun, say, so, early, hor, u, c, already, t...     0.0  0.0  0.0   \n",
       "4   ham  [nah, i, don, t, think, he, goes, to, usf, he,...     0.0  0.0  0.0   \n",
       "5  spam  [freemsg, hey, there, darling, it, s, been, 3,...     0.0  0.0  0.0   \n",
       "\n",
       "   w1jhl  50p  wine  punishment  missed  ...  strips  chloe  mike  sweatter  \\\n",
       "0    0.0  0.0   0.0         0.0     0.0  ...     0.0    0.0   0.0       0.0   \n",
       "1    0.0  0.0   0.0         0.0     0.0  ...     0.0    0.0   0.0       0.0   \n",
       "3    0.0  0.0   0.0         0.0     0.0  ...     0.0    0.0   0.0       0.0   \n",
       "4    0.0  0.0   0.0         0.0     0.0  ...     0.0    0.0   0.0       0.0   \n",
       "5    0.0  0.0   0.0         0.0     0.0  ...     0.0    0.0   0.0       0.0   \n",
       "\n",
       "   cheetos  others  dey  yan  stopbcm  words_sum  \n",
       "0      0.0     0.0  0.0  0.0      0.0         20  \n",
       "1      0.0     0.0  0.0  0.0      0.0          6  \n",
       "3      0.0     0.0  0.0  0.0      0.0         11  \n",
       "4      0.0     0.0  0.0  0.0      0.0         14  \n",
       "5      0.0     0.0  0.0  0.0      0.0         36  \n",
       "\n",
       "[5 rows x 7760 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_training['words_sum'] = wc_training['SMS'].apply(len)\n",
    "wc_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3561\n",
       "Name: words_sum, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_training['words_sum'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all words in spam messages\n",
    "spam_messages = wc_training[wc_training['Label']=='spam']\n",
    "n_spam = spam_messages['words_sum'].sum()\n",
    "\n",
    "#all words in ham messages\n",
    "ham_messages = wc_training[wc_training['Label']=='ham']\n",
    "n_ham = ham_messages['words_sum'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "#laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word, we need to calculate both P(wi|Spam) and P(wi|Ham).\n",
    "\n",
    "We have 7,783 words in our vocabulary, which means we'll need to calculate a total of 15,566 probabilities.\n",
    "\n",
    "We'll initialize two dictionaries, where each key-value pair is a unique word (from the vocabulary) represented as a string, and the value is 0. One dictionary will store the parameters for P(wi|Spam), and the other for P(wi|Ham)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dictionary = {}\n",
    "ham_dictionary = {}\n",
    "\n",
    "for word in vocabulary:\n",
    "    spam_dictionary[word] = [0]\n",
    "    ham_dictionary[word] = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_wi_spam = number of times a word occurs in all spam messages\n",
    "#n_wi_not_spam = number of times a word occurs in all spam messages\n",
    "\n",
    "for word in vocabulary:\n",
    "    n_wi_spam = spam_messages[word].sum()\n",
    "    n_wi_not_spam = ham_messages[word].sum()\n",
    "    \n",
    "    p_wi_spam = (n_wi_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    spam_dictionary[word] = p_wi_spam\n",
    "    \n",
    "    p_wi_not_spam = (n_wi_not_spam + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    ham_dictionary[word] = p_wi_not_spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a filter\n",
    "with all the constants and parameters we need, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "* Takes in as input a new message (w1, w2, ..., wn)\n",
    "* Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)\n",
    "* Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn), and:\n",
    "    * If P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.\n",
    "    * If P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.\n",
    "    *  If P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    #the input is string, clean the message\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    #calculate probabilities\n",
    "    \n",
    "    #initiate variables, priors\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # foreach word find correspnding values in the dictionaries\n",
    "    #update final probability\n",
    "    for word in message:\n",
    "        if word in spam_dictionary:\n",
    "            p_spam_given_message *= spam_dictionary[word]\n",
    "        if word in ham_dictionary:\n",
    "            p_ham_given_message *= ham_dictionary[word]\n",
    "        \n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    #print results!\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 9.800860367363035e-28\n",
      "P(Ham|message): 2.8982188281301195e-25\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "#test funciton\n",
    "m_1 = 'WIN PRIZE!! MEGA secret code to unlock the money: 12X34.'\n",
    "classify(m_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsure why it labels it `ham` where it's clearly spam! Everything is `ham`! :facepalm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 8.892447588598952e-35\n",
      "P(Ham|message): 3.0097341913610213e-31\n",
      "Label: Ham\n",
      "P(Spam|message): 1.7324403485976313e-23\n",
      "P(Ham|message): 2.2862854593486107e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "m_3 = 'WINNER!! This is the secret code to unlock the money money money: C3421.'\n",
    "classify(m_3)\n",
    "\n",
    "m_4 = 'Sounds good, Tom, then see u there'\n",
    "classify(m_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 7.397541643016726e-17\n",
      "P(Ham|message): 7.458644494635064e-15\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "m_2 = 'Wanna grab dinner tomorrow?'\n",
    "classify(m_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the test set\n",
    "\n",
    "We'll try to determine how well the spam filter does on our test set of 1,114 messages.\n",
    "\n",
    "The algorithm will output a classification label for every message in our test set, which we'll be able to compare with the actual label (given by a human).\n",
    "\n",
    "We'll change the `classify()` function that we wrote previously to return the labels instead of printing them. Below, note that we now have return statements instead of `print()` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in spam_dictionary:\n",
    "            p_spam_given_message *= spam_dictionary[word]\n",
    "\n",
    "        if word in ham_dictionary:\n",
    "            p_ham_given_message *= ham_dictionary[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham                           0.995512\n",
       "spam                          0.002693\n",
       "needs human classification    0.001795\n",
       "Name: predicted, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a column in the test set with the predicitons\n",
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set['predicted'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the predicted values with the actual values to measure how good our spam filter is with classifying new messages. To make the measurement, we'll use accuracy as a metric:\n",
    "\n",
    "**Accuracy = correctly classified messages / total number of messages**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filter is 86.62 % accurate.\n",
      "Correctly classified messages: 965 ( 86.62 %)\n",
      "Incorrectly classified messsages: 149 ( 13.38 %)\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "\n",
    "for index, row in test_set.iterrows():\n",
    "    if row['predicted'] == row['Label']:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct/ total\n",
    "accuracy_round = round((accuracy*100),2)\n",
    "print('The filter is',accuracy_round, '% accurate.')\n",
    "print('Correctly classified messages:', correct, '(', accuracy_round, '%)'\"\\n\"\n",
    "     'Incorrectly classified messsages:', total - correct, '(', round(100-accuracy_round,2), '%)'\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Next steps\n",
    "**We initially aimed for an accuracy of over 80%, the filter is 86.62% accurate which is better than expected.**\n",
    "\n",
    "Next steps we can take to increase the accuracy of this filer:\n",
    "* Isolate the 149 messages that were classified incorrectly and try to figure out why the algorithm reached the wrong conclusions.\n",
    "* Make the filtering process more complex by making the algorithm sensitive to letter case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
