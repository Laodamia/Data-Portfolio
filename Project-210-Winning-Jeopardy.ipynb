{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Winning Jeopardy \n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for a few decades, and is a major force in popular culture.\n",
    "\n",
    "The dataset is named jeopardy.csv, and contains 20000 rows from the beginning of a full dataset of Jeopardy questions, [available here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file). \n",
    "\n",
    "Each row in the dataset represents a single question on a single episode of Jeopardy. Here are explanations of each column:\n",
    "\n",
    "* Show Number -- the Jeopardy episode number of the show this question was in.\n",
    "* Air Date -- the date the episode aired.\n",
    "* Round -- the round of Jeopardy that the question was asked in. Jeopardy has several rounds as each episode progresses.\n",
    "* Category -- the category of the question.\n",
    "* Value -- the number of dollars answering the question correctly is worth.\n",
    "* Question -- the text of the question.\n",
    "* Answer -- the text of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fix column names\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy = jeopardy.rename(columns= lambda x: x.strip())\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Before doing analysis on the Jeopardy questions, we need to normalize all of the text columns (the `Question` and `Answer` columns). We want to ensure that we lowercase words and remove punctuation so `Don't` and `don't` aren't considered to be different words when we compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poo'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#normalizaiton function: lower & remove punctuation\n",
    "def normalize(string):\n",
    "    string = str.lower(string)\n",
    "    string = re.sub('[^\\w\\s]', '', string)\n",
    "    return string\n",
    "\n",
    "#test\n",
    "a = 'Poo/.'\n",
    "normalize(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the question & answer columns\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2000\n"
     ]
    }
   ],
   "source": [
    "#turn value col into numeric\n",
    "def turnumeric(string):\n",
    "    s = str.replace(string,\"$\", \"\")\n",
    "    s = re.sub('[^\\w\\s]', '', s)\n",
    "    try:\n",
    "        n = int(s)\n",
    "    except:\n",
    "        n = 0\n",
    "    return n\n",
    "\n",
    "#test\n",
    "a = \"None\"\n",
    "b ='$2,000'\n",
    "print(turnumeric(a), turnumeric(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_value'] = jeopardy['Value'].apply(turnumeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2004-12-31\n",
       "Name: Air Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert air date to datetime\n",
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])\n",
    "\n",
    "#test\n",
    "jeopardy['Air Date'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the topic to study\n",
    "\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "* How often the answer is deducible from the question.\n",
    "* How often new questions are repeats of older questions.\n",
    "\n",
    "We can answer the second question by seeing how often complex words (> 6 characters) reoccur. \n",
    "We can answer the first question by seeing how many times words in the answer also occur in the question. \n",
    "\n",
    "We'll work on the first question now, and come back to the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(row):\n",
    "    #split the cell by white space into list\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    #remove 'the'\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "        \n",
    "    #prevent division by 0 later\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    \n",
    "    match_count = 0\n",
    "    #check how many words in answer occur in the question\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            match_count +=1\n",
    "            \n",
    "    #return proportion of words in the avg answer that are a part of the question\n",
    "    return match_count/len(split_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column with the proportional value\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(splitter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059001965249777744"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find mean answer in question\n",
    "mean_answer_in_q = jeopardy['answer_in_question'].mean()\n",
    "mean_answer_in_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean number of words in the question that are included in the answer is ~0.06, that is 6%. Studying the quesitons has little impact on getting the answers right. We'll have to study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New questions as repeats of old questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to investigate how often new questions are repeats of older ones. We can't completely answer this, because we only have about 10% of the full Jeopardy question dataset, but we can investigate.\n",
    "\n",
    "As a proxy of qusiton overlap we can use the occurence of complex/long words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy_sorted = jeopardy.sort_values('Air Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    #remove short words\n",
    "    for word in split_question:\n",
    "        if len(word) < 6:\n",
    "            split_question.remove(word)\n",
    "    \n",
    "    match_count = 0 \n",
    "    \n",
    "    #add all long words to a total set of words\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "        \n",
    "        #increment the counter of how many times the same word has been used before\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "        \n",
    "        #calc an avg of prev used words contained in a quesiton\n",
    "        if len(split_question) > 0:\n",
    "            match_count = match_count/len(split_question)\n",
    "      \n",
    "    question_overlap.append(match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18957336291968835\n"
     ]
    }
   ],
   "source": [
    "jeopardy['question_overlap'] = question_overlap\n",
    "mean_overlap = jeopardy['question_overlap'].mean()\n",
    "\n",
    "print(mean_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean overlap between quesitons is around 19%. This suggests there is ~1/5 chance that a new question will be related to something that has already been asked about. Studying for topics covered in past questions can increase our chances of doing well in Jeopardy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High value questions\n",
    "Let's say we only want to study questions that pertain to high value questions instead of low value questions. This will help us earn more money on Jeopardy.We can figure out which terms correspond to high-value questions using a chi-squared test. \n",
    "\n",
    "To do it we will divide questions into two categories:\n",
    "\n",
    "* Low value -- Any row where Value is less than 800.\n",
    "* High value -- Any row where Value is greater than 800.\n",
    "\n",
    "We'll then loop through each of the terms from terms_used, and:\n",
    "\n",
    "* Find the number of low value questions the word occurs in.\n",
    "* Find the number of high value questions the word occurs in.\n",
    "* Find the percentage of questions the word occurs in.\n",
    "* Based on the percentage of questions the word occurs in, find expected counts.\n",
    "* Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "\n",
    "We can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: row, output 0/1\n",
    "\n",
    "def check_value(row):\n",
    "    v = 0\n",
    "    if row['clean_value'] > 800:\n",
    "        v = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14265\n",
       "1     5734\n",
       "Name: high_value, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new column\n",
    "jeopardy['high_value'] = jeopardy.apply(check_value, axis=1)\n",
    "#test\n",
    "jeopardy['high_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of times the word appears in the low an high value questions\n",
    "#input: word, output: number of times word is in low/high v quesitons\n",
    "\n",
    "def word_frequency(word):\n",
    "    low_count = 0\n",
    "    high_count = 0 \n",
    "    \n",
    "    for index, row in jeopardy.iterrows():\n",
    "        split_question = row['clean_question'].split()\n",
    "\n",
    "        if word in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count +=1\n",
    "            else:\n",
    "                low_count += 0\n",
    "    return low_count, high_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['northanger', 'blackhearts', 'death', 'multideck', 'exulans']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected = []\n",
    "\n",
    "#convert a set to a list & pick 5 items for comparison\n",
    "comparison_terms = list(terms_used)[:5]\n",
    "comparison_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in comparison_terms:\n",
    "    frequencies = word_frequency(t)\n",
    "    observed_expected.append(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 1), (0, 36), (0, 0), (0, 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the expected counts and the chi-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_value_count = jeopardy[jeopardy['high_value'] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy['high_value'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martakrzeminska/Applications/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:5048: RuntimeWarning: invalid value encountered in true_divide\n",
      "  terms = (f_obs - f_exp)**2 / f_exp\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "for l in observed_expected:\n",
    "    total = sum(l)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    expected_high = total_prop * high_value_count\n",
    "    expected_low = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([l[0],l[1]])\n",
    "    expected = np.array([expected_high,expected_low])\n",
    "    \n",
    "    chi_squared.append(chisquare(observed, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=14.470662460567823, pvalue=0.00014235955089733572),\n",
       " Power_divergenceResult(statistic=nan, pvalue=nan),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "The frequencies of the terms in this set were very low. The pvalues indicate there was no significant diffrence in their appearance in the high and low value questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "Find a better way to eliminate non-informative words than just removing words that are less than 6 characters long. Ideas:\n",
    "* Manually create a list of words to remove, like the, than, etc.\n",
    "* Find a list of stopwords to remove.\n",
    "* Remove words that occur in more than a certain percentage (like 5%) of questions.\n",
    "\n",
    "Perform the chi-squared test across more terms to see what terms have larger differences. This is hard to do currently because the code is slow, but here are some ideas:\n",
    "* Use the apply method to make the code that calculates frequencies more efficient.\n",
    "* Only select terms that have high frequencies across the dataset, and ignore the others.\n",
    "\n",
    "Look more into the Category column and see if any interesting analysis can be done with it. Some ideas:\n",
    "* See which categories appear the most often.\n",
    "* Find the probability of each category appearing in each round.\n",
    "\n",
    "Use the whole Jeopardy dataset ([here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file)) instead of the subset we used above.\n",
    "Use phrases instead of single words when seeing if there's overlap between questions. Single words don't capture the whole context of the question well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "      <th>answer_in_question</th>\n",
       "      <th>question_overlap</th>\n",
       "      <th>high_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number   Air Date      Round                         Category Value  \\\n",
       "0         4680 2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                      clean_question clean_answer  \\\n",
       "0  for the last 8 years of his life galileo was u...   copernicus   \n",
       "1  no 2 1912 olympian football star at carlisle i...   jim thorpe   \n",
       "2  the city of yuma in this state has a record av...      arizona   \n",
       "3  in 1963 live on the art linkletter show this c...    mcdonalds   \n",
       "4  signer of the dec of indep framer of the const...   john adams   \n",
       "\n",
       "   clean_value  answer_in_question  question_overlap  high_value  \n",
       "0          200                 0.0          0.111111           0  \n",
       "1          200                 0.0          0.090909           0  \n",
       "2          200                 0.0          0.111111           0  \n",
       "3          200                 0.0          0.125000           0  \n",
       "4          200                 0.0          0.090909           0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to find the % of questions that have a specific word in them\n",
    "\n",
    "def appear_percentage(word):\n",
    "    appearances_of_word = 0\n",
    "    \n",
    "    for index, row in jeopardy.iterrows():\n",
    "        split_question = row['clean_question'].split()\n",
    "    \n",
    "        if word in split_question:\n",
    "            appearances_of_word += 1\n",
    "            \n",
    "    return appearances_of_word / len(jeopardy['clean_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008600430021501074"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appear_percentage('life')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary of all unique words in questions + times they appear\n",
    "#calculate % of appearances of each word\n",
    "#remove each word that has over 5% of appearances (0.05)\n",
    "\n",
    "jeopardy['split'] = jeopardy['clean_question'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = {}\n",
    "\n",
    "#count frequencies\n",
    "for row in jeopardy['split']:\n",
    "    for word in row:\n",
    "        if word in word_list:\n",
    "            word_list[word] += 1\n",
    "        else:\n",
    "            word_list[word] = 1\n",
    "\n",
    "#convert to %\n",
    "for key, value in word_list.items():\n",
    "    v = value/len(word_list)\n",
    "    word_list[key] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'the', 'of', 'his', 'was', 'this', '2', 'at', 'with', 'city', 'in', 'state', 'has', 'a', 'on', 'its', 'an', 'to', 'named', 'first', 'and', 'from', 'it', 'i', 'you', 'he', 'that', 'one', 'by', 'name', 'is', 'not', 'or', 'who', 'be', 'these', 'country', 'man', 'are', 'as', 'when', 'can', 'seen', 'like', 'new', 'called', 'us', 'have', 'were', 'type', 'she', 'her', 'about', 'but']\n"
     ]
    }
   ],
   "source": [
    "#each of these words constitutes more than 1.3% of all the words\n",
    "freq_words = []\n",
    "\n",
    "for key, value in word_list.items():\n",
    "    if value > 0.013:\n",
    "        freq_words.append(key)\n",
    "        \n",
    "print(freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    last 8 years life galileo under house arrest e...\n",
       "1    no 1912 olympian football star carlisle indian...\n",
       "2    yuma record average 4055 hours sunshine each year\n",
       "3    1963 live art linkletter show company served b...\n",
       "4    signer dec indep framer constitution mass seco...\n",
       "Name: clean_question_1, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove freq words\n",
    "\n",
    "def cleaner(row):\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    #remove each word from the list\n",
    "    resultwords  = [word for word in split_question if word not in freq_words]\n",
    "    result = ' '.join(resultwords)\n",
    "\n",
    "    return result\n",
    "\n",
    "jeopardy['clean_question_1'] = jeopardy.apply(cleaner, axis=1)\n",
    "jeopardy['clean_question_1'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to investigate how often new questions are repeats of older ones. We can't completely answer this, because we only have about 10% of the full Jeopardy question dataset, but we can investigate.\n",
    "\n",
    "As a proxy of qusiton overlap we can use the occurence of complex/long words. This time the list of long words is more precise, as we removed more of the simple/stop words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat the process with overlap\n",
    "question_overlap_1 = []\n",
    "terms_used_1 = set()\n",
    "word_overlap = {}\n",
    "\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question_1'].split()\n",
    "    \n",
    "    #remove short words\n",
    "    for word in split_question:\n",
    "        if len(word) < 6:\n",
    "            split_question.remove(word)\n",
    "    \n",
    "    match_count = 0 \n",
    "    \n",
    "    #add all long words to a total set of words\n",
    "    for word in split_question:\n",
    "        terms_used_1.add(word)\n",
    "        \n",
    "        #increment the counter of how many times the same word has been used before\n",
    "        if word in terms_used_1:\n",
    "            match_count += 1\n",
    "        \n",
    "        #calc an avg of prev used words contained in a quesiton\n",
    "        if len(split_question) > 0:\n",
    "            match_count = match_count/len(split_question)\n",
    "          \n",
    "        # create a dictionary of word + its percentage of overlap\n",
    "        word_overlap[word] = match_count\n",
    "        \n",
    "    question_overlap_1.append(match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28063873856356764\n"
     ]
    }
   ],
   "source": [
    "jeopardy['question_overlap_1'] = question_overlap_1\n",
    "mean_overlap_1 = jeopardy['question_overlap_1'].mean()\n",
    "\n",
    "print(mean_overlap_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overlap is 28% which means that each new question has 28% chance of using a term used in a previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.199996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>life</td>\n",
       "      <td>0.166665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>galileo</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>house</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>arrest</td>\n",
       "      <td>0.199846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         percentage\n",
       "8          0.199996\n",
       "life       0.166665\n",
       "galileo    0.125000\n",
       "house      0.750000\n",
       "arrest     0.199846"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_overlap = pd.DataFrame.from_dict(word_overlap, orient='index', columns=['percentage'])\n",
    "w_overlap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to find all words that lie in the IQR of the overlap. Most common words around the mean. The assumption being they will contain clues of topics that are best to study. The most common ones are probably still fairly common nouns and verbs and the least common ones are less likely to pop up. They are considered outlierrs and will be removed.\n",
    "\n",
    "We'll filter the w_overlap database to show only the words centered around the mean of the overlap value, the IQR of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_overlap.sort_values(by='percentage', inplace=True)\n",
    "\n",
    "#compute IQR\n",
    "Q1 = w_overlap['percentage'].quantile(0.25)\n",
    "Q3 = w_overlap['percentage'].quantile(0.75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter db to show only words in the IQR\n",
    "\n",
    "overlap_iqr = w_overlap[(w_overlap['percentage'] > Q1) & (w_overlap['percentage'] < Q3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We eliminated 15036 elements, and are left with 14648 words.\n"
     ]
    }
   ],
   "source": [
    "w_overlap_len = w_overlap.shape[0]\n",
    "overlap_iqr_len =  overlap_iqr.shape[0]\n",
    "print(\"We eliminated\", w_overlap_len - overlap_iqr_len, \"elements, and are left with\", overlap_iqr_len, \"words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more stats fun, we can also see how this value differs from what'll happen if we only keep values that fall  within 1SD of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage    0.081222\n",
      "dtype: float64 percentage    0.338646\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#calculate SD & pick words within one sd of the mean\n",
    "#ddof = 1 because this is a sample of a whole dataset \n",
    "std = w_overlap.std(axis=0, ddof=1)\n",
    "mean = w_overlap.mean()\n",
    "v1 = mean-std\n",
    "v2 = mean+std\n",
    "print(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to keep only values that fall within 1sd of the mean\n",
    "overlap_1_std = w_overlap[(w_overlap['percentage'] > float(v1)) & (w_overlap['percentage'] < float(v2))]\n",
    "o_1_std_len = overlap_1_std.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 26191 words within 1 std of the mean, which eliminates 3493 words.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", o_1_std_len, \"words within 1 std of the mean, which eliminates\", w_overlap_len-o_1_std_len,\"words.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use IQR to select the most promissing words for the chi square analysis. \n",
    "\n",
    "Using the same funciton as before to calculate freqencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the df to a list\n",
    "iqr_words = overlap_iqr.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hrefhttpwwwjarchivecommedia20030107_dj_26jpg', 'hrefhttpwwwjarchivecommedia20040712_j_23ajpg', 'hrefhttpwwwjarchivecommedia20050502_j_02ajpg', 'hrefhttpwwwjarchivecommedia20060317_j_27jpg', 'hrefhttpwwwjarchivecommedia20040521_j_28jpg']\n",
      "At the moment with all the hrefs the list has 14648 elements.\n"
     ]
    }
   ],
   "source": [
    "hrefs = [x for x in iqr_words if 'href' in x]\n",
    "print(hrefs[:5])\n",
    "print(\"At the moment with all the hrefs the list has\", len(iqr_words), \"elements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many words that seem to be filenames of some kind, ending with jpg or json. It would be best to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing the hrefs the list has 14428 elements.\n"
     ]
    }
   ],
   "source": [
    "iqr_words = [x for x in iqr_words if not 'href' in x]\n",
    "print(\"After removing the hrefs the list has\", len(iqr_words), \"elements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "      <th>high_count</th>\n",
       "      <th>low_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>dragon</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>corps</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        percentage   high_count  low_count\n",
       "dragon    0.142857          NaN        NaN\n",
       "corps     0.142857          NaN        NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create empty columns to store values\n",
    "overlap_iqr = overlap_iqr.reindex(columns= [\"percentage\",\" high_count\", \"low_count\"])\n",
    "overlap_iqr.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I'll need to:\n",
    "reindex the df to be able to pick one item from the row as a WORD to calc the frequences.\n",
    "if that word is in split q we'll assign the counts to the cols in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>percentage</th>\n",
       "      <th>high_count</th>\n",
       "      <th>low_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dragon</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>corps</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  percentage   high_count  low_count\n",
       "0  dragon    0.142857          NaN        NaN\n",
       "1   corps    0.142857          NaN        NaN"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reindex the df\n",
    "# new_index = ['word','percentage','high_count','low_count']\n",
    "# overlap_iqr['word'] = overlap_iqr.index\n",
    "overlap_iqr = overlap_iqr.reset_index()\n",
    "overlap_iqr = overlap_iqr.rename(columns={'index':'word'})\n",
    "overlap_iqr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check number of times the word appears in the low an high value questions\n",
    "#input df with words \n",
    "#output: columns number of times word is in low/high v quesitons\n",
    "\n",
    "def word_frequency_1(word):\n",
    "    low_count = 0\n",
    "    high_count = 0 \n",
    "\n",
    "    for index, row in jeopardy.iterrows():\n",
    "        split_question = row['clean_question_1'].split()\n",
    "    \n",
    "        if word in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count +=1\n",
    "            else:\n",
    "                low_count += 0\n",
    "                \n",
    "    return low_count, high_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dragon', 'corps', 'flawed', 'secret', 'annual']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iqr_5 = iqr_words[:5]\n",
    "iqr_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_expected_1 =[]\n",
    "for t in iqr_5:\n",
    "    frequencies = word_frequency_1(t)\n",
    "    observed_expected_1.append(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3), (0, 8), (0, 1), (0, 11), (0, 5)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>percentage</th>\n",
       "      <th>high_count</th>\n",
       "      <th>low_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dragon</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>corps</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>flawed</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>secret</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>annual</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  percentage   high_count  low_count\n",
       "0  dragon    0.142857          NaN        NaN\n",
       "1   corps    0.142857          NaN        NaN\n",
       "2  flawed    0.142857          NaN        NaN\n",
       "3  secret    0.142857          NaN        NaN\n",
       "4  annual    0.142857          NaN        NaN"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_5 = overlap_iqr[:5]\n",
    "slice_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values(row):\n",
    "    for index, row in slice_5.iterrows():\n",
    "        word = row['word']\n",
    "        low_high = word_frequency_1(word)\n",
    "        slice_5['low_count'] = low_high[0]\n",
    "        slice_5['high_count'] = low_high[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martakrzeminska/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/martakrzeminska/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test = slice_5.apply(count_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
